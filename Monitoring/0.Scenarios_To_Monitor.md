## [Scenarios to monitor](https://learn.microsoft.com/en-us/azure/cosmos-db/use-metrics)


#### [Server side latency metric](https://learn.microsoft.com/en-us/azure/cosmos-db/monitor-server-side-latency)

The server-side latency metric **direct** and server-side latency **gateway** metrics are used to view the server-side latency of an operation in two different connection modes:

- Direct mode
- Gateway mode

![image](https://github.com/napsterhopes/AZ/assets/12064832/ebd79e4e-1176-4b52-bf67-912a68581365)

---

#### Filters

![image](https://github.com/napsterhopes/AZ/assets/12064832/4e74f439-d4c5-4a2e-9241-833f2f18b8c8)

#### [How to monitor normalized RU/s for an Azure Cosmos DB container or an account?](https://learn.microsoft.com/en-us/azure/cosmos-db/monitor-normalized-request-units)

The Normalized RU Consumption metric is a metric between 0% to 100% that is used to help measure the utilization of provisioned throughput on a database or container. 

Each partition key range maps to one physical partition and is assigned to hold data for a range of possible hash values.

The metric can also be used to view the utilization of individual partition key ranges on a database or container.

> How do you calculate normalized RU consumption ?

For example, suppose you have a container where you set autoscale max throughput of 20,000 RU/s (scales between 2000 - 20,000 RU/s) and you have two partition key ranges (physical partitions) P1 and P2. 

Because Azure Cosmos DB distributes the provisioned throughput equally across all the partition key ranges, P1 and P2 each can scale between 1000 - 10,000 RU/s. 

Suppose in a 1 minute interval, in a given second, P1 consumed 6000 request units and P2 consumed 8000 request units. The normalized RU consumption of P1 is 60% and 80% for P2. The overall normalized RU consumption of the entire container is MAX(60%, 80%) = 80%.

> If you want to calculate RUs you need to for your collection. [Here](https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/distribute-throughput-across-partitions?source=recommendations#determine-rus-for-source-partition) is something you can follow.

```
- 5000 stores * 5 devices in each store = Total number of devices => 75000 devices
- As per our partition key on serial number, we would be having 75000 physical partitions
- Our RUs would get divided by 75000. Let's say our current Autoscale max throughput is 20000, then it would be 0.26 RU/sec for a partition key.

- We can also specify a custom minimum throughput each physical partition should have after the redistribution. If not specified, by default, Azure Cosmos DB will ensure that each physical partition has at least 100 RU/s after the redistribution. It's recommended to explicitly specify the minimum throughput.

- Actually, one partition key per day would be having 1440 records (1 device generating telemetry for 12 hours -US consideration).If average size of a document is ~3KB then point opertation on 1440 records would take 4320 RUs
- 75000 devices consuming 4320 RUs in a day amount to 324,000,000
```

```
Increasing the RU/s to Total consumed RU/s of the physical partition + (Number of 429 responses per second * Average RU charge per request to the partition)
```

```
The cost to do a point read (fetching a single item by its ID and partition key value) for a 1-KB item is one Request Unit (or one RU).
The most RU/s any physical partition can contain is 10,000 RU/s.
```

If you're interested in seeing the request unit consumption at a per second interval, along with operation type, you can use the opt-in feature [Diagnostic Logs](https://learn.microsoft.com/en-us/azure/cosmos-db/monitor-resource-logs) and query the **PartitionKeyRUConsumption** table.

---

### [What to expect and do when normalized RU/s is higher](https://learn.microsoft.com/en-us/azure/cosmos-db/monitor-normalized-request-units#what-to-expect-and-do-when-normalized-rus-is-higher)

When the normalized RU consumption reaches 100% for given partition key range, and if a client still makes requests in that time window of 1 second to that specific partition key range - it receives a rate limited error (429).

This doesn't necessarily mean there's a problem with your resource. By default, the **Azure Cosmos DB client SDKs** and data import tools such as Azure Data Factory and bulk executor library **automatically retry requests on 429s**. They retry typically up to 9 times. As a result, while you may see 429s in the metrics, these errors may not even have been returned to your application.

In general, for a production workload, if you see between 1-5% of requests with 429s, and your end to end latency is acceptable, this is a healthy sign that the RU/s are being fully utilized. In this case, the normalized RU consumption metric reaching 100% only means that in a given second, at least one partition key range used all its provisioned throughput. This is acceptable because the overall rate of 429s is still low. No further action is required.

To determine what percent of your requests to your database or container resulted in 429s, from your Azure Cosmos DB account blade, navigate to **Insights > Requests > Total Requests by Status Code**.

![image](https://github.com/napsterhopes/AZ/assets/12064832/e33d5a9b-4c22-4d9c-8e7d-68af2f5c8024)

If the normalized RU consumption metric is consistently 100% across multiple partition key ranges and the rate of 429s is greater than 5%, it's recommended to increase the throughput. 

It isn't always the case that you'll see a 429 rate limiting error just because the normalized RU has reached 100%. That's because the normalized RU is a single value that represents the max usage over all partition key ranges. One partition key range may be busy but the other partition key ranges can serve requests without issues. For example, a single operation such as a stored procedure that consumes all the RU/s on a partition key range will lead to a short spike in the normalized RU consumption metric. In such cases, there won't be any immediate rate limiting errors if the overall request rate is low or requests are made to other partitions on different partition key ranges.

[Learn more about how to interpret and debug 429 rate limiting errors](https://learn.microsoft.com/en-us/azure/cosmos-db/nosql/troubleshoot-request-rate-too-large?tabs=resource-specific#rate-limiting-on-metadata-requests).

---

### [How to monitor for hot partitions](https://learn.microsoft.com/en-us/azure/cosmos-db/monitor-normalized-request-units#how-to-monitor-for-hot-partitions)

The normalized RU consumption metric can be used to monitor if your workload has a hot partition. A hot partition arises when one or a few logical partition keys consume a disproportionate amount of the total RU/s due to higher request volume. This can be caused by a partition key design that doesn't evenly distribute requests. It results in many requests being directed to a small subset of logical partitions (which implies partition key ranges) that become "hot." Because all data for a logical partition resides on one partition key range and total RU/s is evenly distributed among all the partition key ranges, a hot partition can lead to 429s and inefficient use of throughput.

#### [How to identify if there's a hot partition](https://learn.microsoft.com/en-us/azure/cosmos-db/monitor-normalized-request-units#how-to-identify-if-theres-a-hot-partition)

To verify if there's a hot partition, navigate to Insights > Throughput > Normalized RU Consumption (%) By PartitionKeyRangeID. Filter to a specific database and container.

Each PartitionKeyRangeId maps to one physical partition. If there's one PartitionKeyRangeId that has significantly higher normalized RU consumption than others (for example, one is consistently at 100%, but others are at 30% or less), this can be a sign of a hot partition.




